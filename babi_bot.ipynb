{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "babi-bot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEjXWQWAfYHt",
        "outputId": "75b978ea-a7e4-4dfe-fae9-3ba01b64a7c3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "u9r3bVBLfcR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "DiEwzfpwfjIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aOlCyZjogg25"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"train_qa.txt\", \"rb\") as f:\n",
        "    train_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "unfZWIFofjIA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"test_qa.txt\", \"rb\") as f:\n",
        "    test_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "-_UPnsbAge1V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(test_data)\n",
        "type(train_data)\n",
        "len(test_data)\n",
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta4D8rsugoTc",
        "outputId": "2939f3c9-458b-4b1d-8c08-0438c11e1ab9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcI7UZ6NguYg",
        "outputId": "296999b8-f169-41c5-feb4-4063bea756d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "73h6Uexjg0WV",
        "outputId": "3a568ceb-343c-4363-ae86-bbb5b481c5d1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B7dOy9jBg4dv",
        "outputId": "685ef9ab-8237-4813-a0fe-f8d96996d0b5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7VnvOLQ7g6mK",
        "outputId": "15e0a912-d7b0-4905-804b-af95a9902c92"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the vocabulary "
      ],
      "metadata": {
        "id": "4ZcWOkDhg9SM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set() # this will hold the vocab\n",
        "\n",
        "all_data = test_data + train_data"
      ],
      "metadata": {
        "id": "brUtLcnwhAOn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for story, question, answer in all_data:\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))"
      ],
      "metadata": {
        "id": "rzlfDnIIhG94"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "metadata": {
        "id": "OGMAxDD9hRai"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4KO4nkEhXQ1",
        "outputId": "d99a2cdf-a801-46a5-e8c5-c3775919601c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab) + 1 # add an extra space to hold a 0 for Keras' pad sequences\n",
        "\n",
        "max_story_len = max([len(data[0]) for data in all_data])\n",
        "\n",
        "max_story_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuR6kvWqhXwA",
        "outputId": "d4d1302d-a150-44c5-de8a-018edbc3e170"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])\n",
        "\n",
        "max_question_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv5Z-UlVhpr_",
        "outputId": "972776ea-49d6-4ba2-80d6-d1db9ee7be7c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorize Data"
      ],
      "metadata": {
        "id": "oGmbc4cfhvxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYBk9TuJhy9r",
        "outputId": "5dd59df9-b7c9-4df2-f035-6918b12b5eca"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab) + 1"
      ],
      "metadata": {
        "id": "NM6G1ZMoh0Sv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Keras Packages"
      ],
      "metadata": {
        "id": "pMmnICbqh7j0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "cDYQkMERiMjr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences \n",
        "from keras.preprocessing.text import Tokenizer  "
      ],
      "metadata": {
        "id": "LL9W_IyKiAwG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# int-encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)\n",
        "\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8SWb9tQiIo8",
        "outputId": "82269c89-5462-40f1-b694-64676e55c982"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'journeyed': 1,\n",
              " 'is': 2,\n",
              " '.': 3,\n",
              " 'discarded': 4,\n",
              " 'football': 5,\n",
              " 'mary': 6,\n",
              " 'to': 7,\n",
              " 'picked': 8,\n",
              " 'milk': 9,\n",
              " 'left': 10,\n",
              " 'got': 11,\n",
              " '?': 12,\n",
              " 'down': 13,\n",
              " 'garden': 14,\n",
              " 'kitchen': 15,\n",
              " 'no': 16,\n",
              " 'apple': 17,\n",
              " 'went': 18,\n",
              " 'travelled': 19,\n",
              " 'grabbed': 20,\n",
              " 'there': 21,\n",
              " 'sandra': 22,\n",
              " 'took': 23,\n",
              " 'hallway': 24,\n",
              " 'in': 25,\n",
              " 'moved': 26,\n",
              " 'put': 27,\n",
              " 'daniel': 28,\n",
              " 'yes': 29,\n",
              " 'back': 30,\n",
              " 'bedroom': 31,\n",
              " 'dropped': 32,\n",
              " 'the': 33,\n",
              " 'bathroom': 34,\n",
              " 'up': 35,\n",
              " 'john': 36,\n",
              " 'office': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story, question, answer in train_data:\n",
        "\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)\n",
        "\n",
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)\n",
        "\n",
        "print(len(train_story_text))\n",
        "len(train_story_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URRqv0TUif63",
        "outputId": "b1518132-6c69-48ad-ee5d-ea6b3397968d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functionalize Vectorization Process"
      ],
      "metadata": {
        "id": "4Ius_4Qhi3LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_stories(data, \n",
        "                      word_index=tokenizer.word_index, \n",
        "                      max_story_len=max_story_len, \n",
        "                      max_question_len=max_question_len):\n",
        "    '''\n",
        "    INPUT:\n",
        "\n",
        "    data: consisting of Stories, Queries, and Answers\n",
        "    word_index: word index dictionary from tokenizer\n",
        "    max_story_len: the length of the longest story ( used for pad_sequences function )\n",
        "    max_question_len: length of the longest question ( used for pad_sequences function )\n",
        "\n",
        "    OUTPUT:\n",
        "\n",
        "        Vectorizes the stories, questions, and answers into padded sequences. \n",
        "        First loop for every story,query,answer in the data. Then convert raw words\n",
        "        to a word index value. Then append each set to their appropriate output list.\n",
        "        Once converted --> words to numbers, pad the sequences so they are all of equal length.\n",
        "\n",
        "    Returns: above output explanation in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "    # X = Stories\n",
        "    X = []\n",
        "    # Xq = Query\n",
        "    Xq = []\n",
        "    # Y = Correct Answer\n",
        "    Y = []\n",
        "\n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab word index for every word in the story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "\n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # INdex 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "\n",
        "        # Now that y is all zeros and it's known it is just Yes/No\n",
        "        ## We can use numpy logic to create this assignment\n",
        "        y[word_index[answer]] = 1\n",
        "\n",
        "        # Append each set of story,query,answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "\n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained\n",
        "    ## on uniformly long sequences. RETURN TUPLE FOR UNPACKING!!!\n",
        "    return (pad_sequences(X, maxlen=max_story_len), \n",
        "            pad_sequences(Xq, maxlen=max_question_len), \n",
        "            np.array(Y))\n",
        "    "
      ],
      "metadata": {
        "id": "fB32EkMQjCrl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)\n",
        "\n",
        "print(inputs_test)\n",
        "queries_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGHIs8HMlD4o",
        "outputId": "984bb2bf-b9a8-4247-c04b-a6dc4fe80c5b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0 ... 33 31  3]\n",
            " [ 0  0  0 ... 33 14  3]\n",
            " [ 0  0  0 ... 33 14  3]\n",
            " ...\n",
            " [ 0  0  0 ... 33 17  3]\n",
            " [ 0  0  0 ... 33 14  3]\n",
            " [ 0  0  0 ... 17 21  3]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2, 36, 25, 33, 15, 12],\n",
              "       [ 2, 36, 25, 33, 15, 12],\n",
              "       [ 2, 36, 25, 33, 14, 12],\n",
              "       ...,\n",
              "       [ 2,  6, 25, 33, 31, 12],\n",
              "       [ 2, 22, 25, 33, 14, 12],\n",
              "       [ 2,  6, 25, 33, 14, 12]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(answers_test)\n",
        "print(sum(answers_test))\n",
        "print(tokenizer.word_index['yes'])\n",
        "tokenizer.word_index['no']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj8CsjmZmVgp",
        "outputId": "6bff3f0b-b84c-4013-f7c5-7fcc90e01f37"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0. 503.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0. 497.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "29\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Model"
      ],
      "metadata": {
        "id": "0TVBAwjTmgCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT RELATIVE PACKAGES\n",
        "from keras.models import Sequential, Model \n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout \n",
        "from keras.layers import add, dot, concatenate \n",
        "from keras.layers import LSTM"
      ],
      "metadata": {
        "id": "ucc1fiiamlVm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Placeholders for Inputs\n",
        "\n",
        "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
      ],
      "metadata": {
        "id": "lbW0DYNBnp-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "metadata": {
        "id": "L7bS23ycnrF4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoders\n",
        "\n",
        "### Input Encoder m"
      ],
      "metadata": {
        "id": "-6lz_nwlm4h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))"
      ],
      "metadata": {
        "id": "LWoJkAf0nM3P"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Encoder c"
      ],
      "metadata": {
        "id": "RcI8na7XoSP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))"
      ],
      "metadata": {
        "id": "XItDJV2ooUt9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question Encoder"
      ],
      "metadata": {
        "id": "BP0y_HjLolMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n"
      ],
      "metadata": {
        "id": "iV1TqSC8opOc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode the Sequences"
      ],
      "metadata": {
        "id": "gKji55lRo6ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encode input sequence and questions ( which are indicies )\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "metadata": {
        "id": "_HMxygP0o9_n"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USE DOT PRODUCT TO COMPUTE THE MATCH BETWEEN FIRST INPUT VECTOR AND QUERY\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation(\"softmax\")(match)"
      ],
      "metadata": {
        "id": "EPZXpOy7pYVt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])\n",
        "response = Permute((2, 1))(response)"
      ],
      "metadata": {
        "id": "DGB5QOKPprlX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONCATENATE\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "metadata": {
        "id": "p-IavOLCqZtU"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAM6DfT8qfmq",
        "outputId": "856adb3f-1608-45de-c6fd-aaf07408fd3b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)"
      ],
      "metadata": {
        "id": "r6SNn9iTqgjJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)"
      ],
      "metadata": {
        "id": "2NrwYmILqoBR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = Activation(\"softmax\")(answer)\n",
        "\n",
        "# build final model \n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer=\"rmsprop\", \n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Ytws2pO8qsna"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvsTrhOtq9Mq",
        "outputId": "7a140103-216b-404f-f4d2-845245d5b6fa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 156)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, None, 64)     2432        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 6, 64)        2432        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 156, 6)       0           ['sequential[0][0]',             \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, None, 6)      228         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
            "                                                                  'sequential_1[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 6, 220)       0           ['permute[0][0]',                \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 32)           32384       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN\n",
        "history = model.fit([inputs_train, queries_train],\n",
        "                    answers_train,\n",
        "                    batch_size=32,\n",
        "                    epochs=120,\n",
        "                    validation_data=([inputs_test, queries_test],\n",
        "                                     answers_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogsdRlJBq-AN",
        "outputId": "3abb1eae-7e46-4c09-b4aa-d60c74e95e35"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "313/313 [==============================] - 9s 18ms/step - loss: 0.9103 - accuracy: 0.4932 - val_loss: 0.6941 - val_accuracy: 0.5030\n",
            "Epoch 2/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.7030 - accuracy: 0.4979 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
            "Epoch 3/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6961 - accuracy: 0.4995 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
            "Epoch 4/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6946 - accuracy: 0.4972 - val_loss: 0.6947 - val_accuracy: 0.4970\n",
            "Epoch 5/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6952 - accuracy: 0.4928 - val_loss: 0.6932 - val_accuracy: 0.4750\n",
            "Epoch 6/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6943 - accuracy: 0.5052 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
            "Epoch 7/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6947 - accuracy: 0.4985 - val_loss: 0.6933 - val_accuracy: 0.4980\n",
            "Epoch 8/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6948 - accuracy: 0.4957 - val_loss: 0.6938 - val_accuracy: 0.5030\n",
            "Epoch 9/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6939 - accuracy: 0.5049 - val_loss: 0.6948 - val_accuracy: 0.4860\n",
            "Epoch 10/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6935 - accuracy: 0.5097 - val_loss: 0.6950 - val_accuracy: 0.4840\n",
            "Epoch 11/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.6870 - accuracy: 0.5296 - val_loss: 0.6850 - val_accuracy: 0.5240\n",
            "Epoch 12/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6676 - accuracy: 0.5726 - val_loss: 0.6595 - val_accuracy: 0.5720\n",
            "Epoch 13/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6546 - accuracy: 0.6068 - val_loss: 0.6455 - val_accuracy: 0.6620\n",
            "Epoch 14/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6380 - accuracy: 0.6424 - val_loss: 0.6238 - val_accuracy: 0.6560\n",
            "Epoch 15/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6272 - accuracy: 0.6520 - val_loss: 0.6208 - val_accuracy: 0.6720\n",
            "Epoch 16/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6233 - accuracy: 0.6568 - val_loss: 0.6134 - val_accuracy: 0.6730\n",
            "Epoch 17/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6202 - accuracy: 0.6579 - val_loss: 0.6128 - val_accuracy: 0.6630\n",
            "Epoch 18/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6125 - accuracy: 0.6675 - val_loss: 0.6095 - val_accuracy: 0.6710\n",
            "Epoch 19/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6087 - accuracy: 0.6678 - val_loss: 0.6038 - val_accuracy: 0.6740\n",
            "Epoch 20/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.6027 - accuracy: 0.6748 - val_loss: 0.6007 - val_accuracy: 0.6700\n",
            "Epoch 21/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5958 - accuracy: 0.6811 - val_loss: 0.5910 - val_accuracy: 0.6830\n",
            "Epoch 22/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5934 - accuracy: 0.6911 - val_loss: 0.5887 - val_accuracy: 0.6890\n",
            "Epoch 23/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5822 - accuracy: 0.6986 - val_loss: 0.5757 - val_accuracy: 0.6950\n",
            "Epoch 24/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5714 - accuracy: 0.7069 - val_loss: 0.5700 - val_accuracy: 0.7070\n",
            "Epoch 25/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.5636 - accuracy: 0.7087 - val_loss: 0.5624 - val_accuracy: 0.7090\n",
            "Epoch 26/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.5465 - accuracy: 0.7204 - val_loss: 0.5463 - val_accuracy: 0.7130\n",
            "Epoch 27/120\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.5376 - accuracy: 0.7292 - val_loss: 0.5289 - val_accuracy: 0.7280\n",
            "Epoch 28/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5220 - accuracy: 0.7388 - val_loss: 0.5201 - val_accuracy: 0.7320\n",
            "Epoch 29/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.5092 - accuracy: 0.7463 - val_loss: 0.5130 - val_accuracy: 0.7360\n",
            "Epoch 30/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4992 - accuracy: 0.7527 - val_loss: 0.5208 - val_accuracy: 0.7310\n",
            "Epoch 31/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.4912 - accuracy: 0.7566 - val_loss: 0.5367 - val_accuracy: 0.7180\n",
            "Epoch 32/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.4832 - accuracy: 0.7610 - val_loss: 0.5211 - val_accuracy: 0.7410\n",
            "Epoch 33/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.4757 - accuracy: 0.7705 - val_loss: 0.5032 - val_accuracy: 0.7420\n",
            "Epoch 34/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4642 - accuracy: 0.7718 - val_loss: 0.4986 - val_accuracy: 0.7470\n",
            "Epoch 35/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4549 - accuracy: 0.7783 - val_loss: 0.4676 - val_accuracy: 0.7780\n",
            "Epoch 36/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4498 - accuracy: 0.7844 - val_loss: 0.4690 - val_accuracy: 0.7880\n",
            "Epoch 37/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4390 - accuracy: 0.7921 - val_loss: 0.4585 - val_accuracy: 0.7940\n",
            "Epoch 38/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4275 - accuracy: 0.7974 - val_loss: 0.4559 - val_accuracy: 0.7850\n",
            "Epoch 39/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4243 - accuracy: 0.8007 - val_loss: 0.4568 - val_accuracy: 0.7890\n",
            "Epoch 40/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4207 - accuracy: 0.8036 - val_loss: 0.4751 - val_accuracy: 0.7850\n",
            "Epoch 41/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4179 - accuracy: 0.8070 - val_loss: 0.4447 - val_accuracy: 0.7950\n",
            "Epoch 42/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4134 - accuracy: 0.8139 - val_loss: 0.5072 - val_accuracy: 0.7860\n",
            "Epoch 43/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4111 - accuracy: 0.8137 - val_loss: 0.4385 - val_accuracy: 0.7960\n",
            "Epoch 44/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4016 - accuracy: 0.8192 - val_loss: 0.4513 - val_accuracy: 0.7890\n",
            "Epoch 45/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.4028 - accuracy: 0.8152 - val_loss: 0.4428 - val_accuracy: 0.8100\n",
            "Epoch 46/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3969 - accuracy: 0.8183 - val_loss: 0.4457 - val_accuracy: 0.7980\n",
            "Epoch 47/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3938 - accuracy: 0.8223 - val_loss: 0.4343 - val_accuracy: 0.8090\n",
            "Epoch 48/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3882 - accuracy: 0.8250 - val_loss: 0.4408 - val_accuracy: 0.8090\n",
            "Epoch 49/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3866 - accuracy: 0.8286 - val_loss: 0.4135 - val_accuracy: 0.8130\n",
            "Epoch 50/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3787 - accuracy: 0.8294 - val_loss: 0.4338 - val_accuracy: 0.8140\n",
            "Epoch 51/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3747 - accuracy: 0.8331 - val_loss: 0.4233 - val_accuracy: 0.8100\n",
            "Epoch 52/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3713 - accuracy: 0.8322 - val_loss: 0.4049 - val_accuracy: 0.8160\n",
            "Epoch 53/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3732 - accuracy: 0.8354 - val_loss: 0.4361 - val_accuracy: 0.8130\n",
            "Epoch 54/120\n",
            "313/313 [==============================] - 6s 18ms/step - loss: 0.3721 - accuracy: 0.8354 - val_loss: 0.4222 - val_accuracy: 0.8090\n",
            "Epoch 55/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3621 - accuracy: 0.8393 - val_loss: 0.3936 - val_accuracy: 0.8200\n",
            "Epoch 56/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3610 - accuracy: 0.8405 - val_loss: 0.4051 - val_accuracy: 0.8260\n",
            "Epoch 57/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3568 - accuracy: 0.8430 - val_loss: 0.4112 - val_accuracy: 0.8200\n",
            "Epoch 58/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3536 - accuracy: 0.8415 - val_loss: 0.3968 - val_accuracy: 0.8270\n",
            "Epoch 59/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3544 - accuracy: 0.8426 - val_loss: 0.4114 - val_accuracy: 0.8140\n",
            "Epoch 60/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3462 - accuracy: 0.8487 - val_loss: 0.4072 - val_accuracy: 0.8190\n",
            "Epoch 61/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3443 - accuracy: 0.8463 - val_loss: 0.4004 - val_accuracy: 0.8150\n",
            "Epoch 62/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3462 - accuracy: 0.8472 - val_loss: 0.4063 - val_accuracy: 0.8240\n",
            "Epoch 63/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3418 - accuracy: 0.8530 - val_loss: 0.4056 - val_accuracy: 0.8190\n",
            "Epoch 64/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3405 - accuracy: 0.8493 - val_loss: 0.4046 - val_accuracy: 0.8150\n",
            "Epoch 65/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3342 - accuracy: 0.8489 - val_loss: 0.4129 - val_accuracy: 0.8300\n",
            "Epoch 66/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3351 - accuracy: 0.8528 - val_loss: 0.4000 - val_accuracy: 0.8160\n",
            "Epoch 67/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3321 - accuracy: 0.8553 - val_loss: 0.3995 - val_accuracy: 0.8190\n",
            "Epoch 68/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3287 - accuracy: 0.8576 - val_loss: 0.4006 - val_accuracy: 0.8170\n",
            "Epoch 69/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3346 - accuracy: 0.8583 - val_loss: 0.4913 - val_accuracy: 0.8070\n",
            "Epoch 70/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3247 - accuracy: 0.8627 - val_loss: 0.4727 - val_accuracy: 0.8190\n",
            "Epoch 71/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3255 - accuracy: 0.8595 - val_loss: 0.4067 - val_accuracy: 0.8200\n",
            "Epoch 72/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3237 - accuracy: 0.8589 - val_loss: 0.3999 - val_accuracy: 0.8290\n",
            "Epoch 73/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3216 - accuracy: 0.8611 - val_loss: 0.4246 - val_accuracy: 0.8190\n",
            "Epoch 74/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3182 - accuracy: 0.8635 - val_loss: 0.4262 - val_accuracy: 0.8270\n",
            "Epoch 75/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3139 - accuracy: 0.8637 - val_loss: 0.4258 - val_accuracy: 0.8250\n",
            "Epoch 76/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3159 - accuracy: 0.8597 - val_loss: 0.4215 - val_accuracy: 0.8210\n",
            "Epoch 77/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.3199 - accuracy: 0.8622 - val_loss: 0.4186 - val_accuracy: 0.8280\n",
            "Epoch 78/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3155 - accuracy: 0.8645 - val_loss: 0.4413 - val_accuracy: 0.8230\n",
            "Epoch 79/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3069 - accuracy: 0.8695 - val_loss: 0.4298 - val_accuracy: 0.8220\n",
            "Epoch 80/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3070 - accuracy: 0.8662 - val_loss: 0.4397 - val_accuracy: 0.8230\n",
            "Epoch 81/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3047 - accuracy: 0.8684 - val_loss: 0.4111 - val_accuracy: 0.8250\n",
            "Epoch 82/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.3036 - accuracy: 0.8683 - val_loss: 0.4486 - val_accuracy: 0.8200\n",
            "Epoch 83/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3046 - accuracy: 0.8685 - val_loss: 0.4362 - val_accuracy: 0.8210\n",
            "Epoch 84/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3019 - accuracy: 0.8688 - val_loss: 0.4474 - val_accuracy: 0.8180\n",
            "Epoch 85/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2991 - accuracy: 0.8695 - val_loss: 0.4241 - val_accuracy: 0.8290\n",
            "Epoch 86/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2927 - accuracy: 0.8713 - val_loss: 0.4650 - val_accuracy: 0.8100\n",
            "Epoch 87/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2992 - accuracy: 0.8707 - val_loss: 0.4298 - val_accuracy: 0.8220\n",
            "Epoch 88/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2984 - accuracy: 0.8741 - val_loss: 0.4331 - val_accuracy: 0.8250\n",
            "Epoch 89/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2975 - accuracy: 0.8726 - val_loss: 0.4223 - val_accuracy: 0.8270\n",
            "Epoch 90/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.3011 - accuracy: 0.8686 - val_loss: 0.4467 - val_accuracy: 0.8200\n",
            "Epoch 91/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2920 - accuracy: 0.8742 - val_loss: 0.4343 - val_accuracy: 0.8320\n",
            "Epoch 92/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2827 - accuracy: 0.8775 - val_loss: 0.4491 - val_accuracy: 0.8270\n",
            "Epoch 93/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2898 - accuracy: 0.8755 - val_loss: 0.4305 - val_accuracy: 0.8320\n",
            "Epoch 94/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2819 - accuracy: 0.8822 - val_loss: 0.4472 - val_accuracy: 0.8130\n",
            "Epoch 95/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2806 - accuracy: 0.8807 - val_loss: 0.4406 - val_accuracy: 0.8270\n",
            "Epoch 96/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2831 - accuracy: 0.8821 - val_loss: 0.4843 - val_accuracy: 0.8280\n",
            "Epoch 97/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2814 - accuracy: 0.8787 - val_loss: 0.4686 - val_accuracy: 0.8180\n",
            "Epoch 98/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2742 - accuracy: 0.8832 - val_loss: 0.5134 - val_accuracy: 0.8190\n",
            "Epoch 99/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2738 - accuracy: 0.8784 - val_loss: 0.4557 - val_accuracy: 0.8250\n",
            "Epoch 100/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2866 - accuracy: 0.8798 - val_loss: 0.4681 - val_accuracy: 0.8110\n",
            "Epoch 101/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2780 - accuracy: 0.8808 - val_loss: 0.4386 - val_accuracy: 0.8220\n",
            "Epoch 102/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2774 - accuracy: 0.8807 - val_loss: 0.4817 - val_accuracy: 0.8190\n",
            "Epoch 103/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2813 - accuracy: 0.8795 - val_loss: 0.4791 - val_accuracy: 0.8160\n",
            "Epoch 104/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2690 - accuracy: 0.8849 - val_loss: 0.4732 - val_accuracy: 0.8240\n",
            "Epoch 105/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2788 - accuracy: 0.8817 - val_loss: 0.4709 - val_accuracy: 0.8200\n",
            "Epoch 106/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2674 - accuracy: 0.8871 - val_loss: 0.4884 - val_accuracy: 0.8100\n",
            "Epoch 107/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2691 - accuracy: 0.8885 - val_loss: 0.4774 - val_accuracy: 0.8200\n",
            "Epoch 108/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.2712 - accuracy: 0.8824 - val_loss: 0.4770 - val_accuracy: 0.8250\n",
            "Epoch 109/120\n",
            "313/313 [==============================] - 6s 19ms/step - loss: 0.2611 - accuracy: 0.8885 - val_loss: 0.4732 - val_accuracy: 0.8260\n",
            "Epoch 110/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2678 - accuracy: 0.8888 - val_loss: 0.4894 - val_accuracy: 0.8180\n",
            "Epoch 111/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2703 - accuracy: 0.8865 - val_loss: 0.4911 - val_accuracy: 0.8220\n",
            "Epoch 112/120\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2633 - accuracy: 0.8912 - val_loss: 0.5047 - val_accuracy: 0.8120\n",
            "Epoch 113/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2626 - accuracy: 0.8875 - val_loss: 0.5266 - val_accuracy: 0.8080\n",
            "Epoch 114/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2617 - accuracy: 0.8887 - val_loss: 0.5066 - val_accuracy: 0.8170\n",
            "Epoch 115/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2667 - accuracy: 0.8841 - val_loss: 0.4851 - val_accuracy: 0.8160\n",
            "Epoch 116/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2566 - accuracy: 0.8920 - val_loss: 0.5064 - val_accuracy: 0.8230\n",
            "Epoch 117/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2654 - accuracy: 0.8897 - val_loss: 0.5022 - val_accuracy: 0.8180\n",
            "Epoch 118/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2570 - accuracy: 0.8899 - val_loss: 0.5055 - val_accuracy: 0.8280\n",
            "Epoch 119/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2622 - accuracy: 0.8914 - val_loss: 0.5146 - val_accuracy: 0.8310\n",
            "Epoch 120/120\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.2536 - accuracy: 0.8941 - val_loss: 0.5180 - val_accuracy: 0.8070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "C7nd1vlMrVKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"chatteral_thinking_120_epochs.h5\"\n",
        "model.save(filename)"
      ],
      "metadata": {
        "id": "bBdfrwoKrjC9"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Model\n",
        "\n",
        "### Plotting Training History"
      ],
      "metadata": {
        "id": "eKPih0SursnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print(history.history.keys())\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "TgeNEuj-r0bb",
        "outputId": "749f632f-c0d2-46ca-8d17-e7e5b9e76061"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on Given Test Set"
      ],
      "metadata": {
        "id": "JDOeLsBdsQsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))\n",
        "\n",
        "test_data[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FvFyHzjsf3Q",
        "outputId": "f02dd893-d65f-480b-9ade-89b1e655a92f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'got',\n",
              " 'the',\n",
              " 'milk',\n",
              " 'there',\n",
              " '.',\n",
              " 'John',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "story = ' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKsoLuDisnrL",
        "outputId": "ee2bd0ce-d09d-430a-b416-40acc740fe24"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMXI1sxJsscZ",
        "outputId": "e6a86a48-aac3-48cf-dc6f-2d62477047e6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is John in the kitchen ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"True Test Answer from Data is: \", test_data[0][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnf6jEE-sxr-",
        "outputId": "2d3ff503-bb3a-49db-9784-48ff6383f274"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Test Answer from Data is:  no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F883rA08s2ue",
        "outputId": "d12ac673-562d-4331-f6a9-5c4841165e9f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.97968125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## test run "
      ],
      "metadata": {
        "id": "ewmFv-zxtM85"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZXvWwSntT9h",
        "outputId": "340df98a-77d8-4fe1-f6c2-bf3c9e6e6c58"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbstnDZZtU6B",
        "outputId": "54fcb759-2bbc-429a-a257-8a80936bfe76"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_question = \"Is the football in the garden ?\""
      ],
      "metadata": {
        "id": "CKqjmmpMteJh"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_question.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90TZqmI6tiSb",
        "outputId": "dc34696a-5d41-4fd6-e5c5-6d0d2260c4ea"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydata = [(my_story.split(), my_question.split(), 'yes')]"
      ],
      "metadata": {
        "id": "ZFfwluSCtkBw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_story, my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "metadata": {
        "id": "Tc94aROztor3"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results = model.predict(([my_story, my_ques]))"
      ],
      "metadata": {
        "id": "ASZDabYItuFE"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### GENERATE FINAL PREDICTION FROM MODEL\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key \n",
        "\n",
        "print(f\"Predicted answer is: {k}\")\n",
        "print(f\"Probability of Certainty was: {pred_results[0][val_max]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma2ZR0bstyq9",
        "outputId": "019cc778-80d2-4e5a-d500-dc3f7e787117"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is: yes\n",
            "Probability of Certainty was: 0.997403085231781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4FGgwmGzuXcH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}